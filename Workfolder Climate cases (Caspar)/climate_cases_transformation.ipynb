{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15bf9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c68b41",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fb3a8",
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\ninput_folder = \"database_downloads\"  # Relative path to the database_downloads folder\noutput_file = \"combined_climate_data.csv\"  # Output file name\n\n# Columns to keep\ncolumns_to_keep = [\n    'Bundle ID(s)',  # Needed for deduplication\n    'Case Filing Year for Action',\n    'Status',\n    'Case Categories',\n    'Geographies'\n    # Add 'sector' column name here if you identify it\n]\n\n# Initialize list to store dataframes\nall_data = []\n\n# Process each CSV file in the folder\nfor csv_file in Path(input_folder).glob(\"*.csv\"):\n    print(f\"Processing: {csv_file.name}\")\n    \n    # Read the CSV\n    df = pd.read_csv(csv_file)\n    \n    # Add a category column based on the filename (without extension)\n    category_name = csv_file.stem  # stem gives filename without extension\n    df['Category'] = category_name\n    \n    # Keep only the columns we need\n    df = df[columns_to_keep + ['Category']]\n    \n    # Add to our list\n    all_data.append(df)\n    print(f\"  Loaded {len(df)} rows from {csv_file.name}\")\n\n# Combine all dataframes\ncombined_df = pd.concat(all_data, ignore_index=True)\nprint(f\"\\nTotal rows before processing: {len(combined_df)}\")\n\n# Create a binary indicator for each category\ncombined_df['value'] = 1\n\n# Pivot to create category columns\ncategory_pivot = combined_df.pivot_table(\n    index='Bundle ID(s)',\n    columns='Category',\n    values='value',\n    aggfunc='max',\n    fill_value=0\n).reset_index()\n\n# Get the other columns (take first occurrence for each Bundle ID)\nother_columns = combined_df.drop(columns=['Category', 'value']).drop_duplicates(subset='Bundle ID(s)', keep='first')\n\n# Merge everything together\nfinal_df = other_columns.merge(category_pivot, on='Bundle ID(s)')\n\nprint(f\"Total unique cases: {len(final_df)}\")\n\n# Save the result\nfinal_df.to_csv(output_file, index=False)\nprint(f\"\\nSaved to: {output_file}\")\n\n# Show which cases appear in multiple categories\ncategory_columns = [col for col in final_df.columns if col not in columns_to_keep]\nfinal_df['total_categories'] = final_df[category_columns].sum(axis=1)\n\nprint(\"\\nCases appearing in multiple categories:\")\nprint(final_df[final_df['total_categories'] > 1]['total_categories'].value_counts().sort_index())\n\nprint(\"\\nCategory column summary:\")\nfor col in category_columns:\n    print(f\"  {col}: {final_df[col].sum()} cases\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z194z2jn2xn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geography Statistics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GEOGRAPHY STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Count total cases\n",
    "total_cases = len(final_df)\n",
    "print(f\"\\nTotal cases: {total_cases}\")\n",
    "\n",
    "# Analyze Geographies column\n",
    "# Note: Each row might contain multiple geographies separated by delimiters\n",
    "geography_counts = {}\n",
    "\n",
    "for idx, row in final_df.iterrows():\n",
    "    geographies = str(row['Geographies'])\n",
    "    \n",
    "    # Skip if NaN or empty\n",
    "    if pd.isna(row['Geographies']) or geographies == 'nan':\n",
    "        geography_counts['Unknown/Not Specified'] = geography_counts.get('Unknown/Not Specified', 0) + 1\n",
    "    else:\n",
    "        # Split by common delimiters (adjust based on your data format)\n",
    "        # Common delimiters: semicolon, comma, pipe\n",
    "        import re\n",
    "        geo_list = re.split(r'[;,|]', geographies)\n",
    "        \n",
    "        for geo in geo_list:\n",
    "            geo = geo.strip()\n",
    "            if geo:\n",
    "                geography_counts[geo] = geography_counts.get(geo, 0) + 1\n",
    "\n",
    "# Convert to DataFrame for better display\n",
    "geography_stats = pd.DataFrame([\n",
    "    {'Geography': geo, 'Count': count, 'Percentage': (count/total_cases)*100}\n",
    "    for geo, count in sorted(geography_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "])\n",
    "\n",
    "print(\"\\nGeography Distribution:\")\n",
    "print(geography_stats.to_string(index=False))\n",
    "\n",
    "print(f\"\\nTotal unique geographies: {len(geography_counts)}\")\n",
    "\n",
    "# Optional: Create a simple bar chart\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show top 15 geographies\n",
    "top_n = 15\n",
    "top_geographies = geography_stats.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(top_geographies)), top_geographies['Count'])\n",
    "plt.yticks(range(len(top_geographies)), top_geographies['Geography'])\n",
    "plt.xlabel('Number of Cases')\n",
    "plt.ylabel('Geography')\n",
    "plt.title(f'Top {top_n} Geographies by Case Count')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save statistics to CSV\n",
    "geography_stats.to_csv('geography_statistics.csv', index=False)\n",
    "print(\"\\nGeography statistics saved to: geography_statistics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff460f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographies\n",
      "USA;US-DC    253\n",
      "USA;US-CA    135\n",
      "BRA;BR-PA     73\n",
      "BRA           72\n",
      "USA;US-NY     65\n",
      "XAB           58\n",
      "USA           53\n",
      "GBR           48\n",
      "USA;US-AK     41\n",
      "BRA;BR-AM     40\n",
      "USA;US-WA     36\n",
      "USA;US-OR     36\n",
      "NZL           27\n",
      "USA;US-MT     24\n",
      "AUS           23\n",
      "USA;US-MA     23\n",
      "USA;US-TX     22\n",
      "USA;US-LA     20\n",
      "USA;US-MD     19\n",
      "USA;US-AZ     17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load  CSV\n",
    "df = pd.read_csv('combined_climate_data.csv')\n",
    "\n",
    "# Show top 10 most common values in the 'Geographies' column\n",
    "print(df['Geographies'].value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93fc73f",
   "metadata": {},
   "source": [
    "the most listed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ac144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gds25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}