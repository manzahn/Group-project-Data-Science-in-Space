{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c68b41",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fb3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "input_folder = \"path/to/your/csv/folder\"  # Change this to your folder path\n",
    "output_file = \"combined_climate_data.csv\"  # Output file name\n",
    "\n",
    "# Columns to keep\n",
    "columns_to_keep = [\n",
    "    'Bundle ID(s)',  # Needed for deduplication\n",
    "    'Case Filing Year for Action',\n",
    "    'Status',\n",
    "    'Case Categories',\n",
    "    'Geographies'\n",
    "    # Add 'sector' column name here if you identify it\n",
    "]\n",
    "\n",
    "# Initialize list to store dataframes\n",
    "all_data = []\n",
    "\n",
    "# Process each CSV file in the folder\n",
    "for csv_file in Path(input_folder).glob(\"*.csv\"):\n",
    "    print(f\"Processing: {csv_file.name}\")\n",
    "    \n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Add a category column based on the filename (without extension)\n",
    "    category_name = csv_file.stem  # stem gives filename without extension\n",
    "    df['Category'] = category_name\n",
    "    \n",
    "    # Keep only the columns we need\n",
    "    df = df[columns_to_keep + ['Category']]\n",
    "    \n",
    "    # Add to our list\n",
    "    all_data.append(df)\n",
    "    print(f\"  Loaded {len(df)} rows from {csv_file.name}\")\n",
    "\n",
    "# Combine all dataframes\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "print(f\"\\nTotal rows before processing: {len(combined_df)}\")\n",
    "\n",
    "# Create a binary indicator for each category\n",
    "combined_df['value'] = 1\n",
    "\n",
    "# Pivot to create category columns\n",
    "category_pivot = combined_df.pivot_table(\n",
    "    index='Bundle ID(s)',\n",
    "    columns='Category',\n",
    "    values='value',\n",
    "    aggfunc='max',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Get the other columns (take first occurrence for each Bundle ID)\n",
    "other_columns = combined_df.drop(columns=['Category', 'value']).drop_duplicates(subset='Bundle ID(s)', keep='first')\n",
    "\n",
    "# Merge everything together\n",
    "final_df = other_columns.merge(category_pivot, on='Bundle ID(s)')\n",
    "\n",
    "print(f\"Total unique cases: {len(final_df)}\")\n",
    "\n",
    "# Save the result\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nSaved to: {output_file}\")\n",
    "\n",
    "# Show which cases appear in multiple categories\n",
    "category_columns = [col for col in final_df.columns if col not in columns_to_keep]\n",
    "final_df['total_categories'] = final_df[category_columns].sum(axis=1)\n",
    "\n",
    "print(\"\\nCases appearing in multiple categories:\")\n",
    "print(final_df[final_df['total_categories'] > 1]['total_categories'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nCategory column summary:\")\n",
    "for col in category_columns:\n",
    "    print(f\"  {col}: {final_df[col].sum()} cases\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "z194z2jn2xn",
   "source": "# Geography Statistics\nprint(\"\\n\" + \"=\"*50)\nprint(\"GEOGRAPHY STATISTICS\")\nprint(\"=\"*50)\n\n# Count total cases\ntotal_cases = len(final_df)\nprint(f\"\\nTotal cases: {total_cases}\")\n\n# Analyze Geographies column\n# Note: Each row might contain multiple geographies separated by delimiters\ngeography_counts = {}\n\nfor idx, row in final_df.iterrows():\n    geographies = str(row['Geographies'])\n    \n    # Skip if NaN or empty\n    if pd.isna(row['Geographies']) or geographies == 'nan':\n        geography_counts['Unknown/Not Specified'] = geography_counts.get('Unknown/Not Specified', 0) + 1\n    else:\n        # Split by common delimiters (adjust based on your data format)\n        # Common delimiters: semicolon, comma, pipe\n        import re\n        geo_list = re.split(r'[;,|]', geographies)\n        \n        for geo in geo_list:\n            geo = geo.strip()\n            if geo:\n                geography_counts[geo] = geography_counts.get(geo, 0) + 1\n\n# Convert to DataFrame for better display\ngeography_stats = pd.DataFrame([\n    {'Geography': geo, 'Count': count, 'Percentage': (count/total_cases)*100}\n    for geo, count in sorted(geography_counts.items(), key=lambda x: x[1], reverse=True)\n])\n\nprint(\"\\nGeography Distribution:\")\nprint(geography_stats.to_string(index=False))\n\nprint(f\"\\nTotal unique geographies: {len(geography_counts)}\")\n\n# Optional: Create a simple bar chart\nimport matplotlib.pyplot as plt\n\n# Show top 15 geographies\ntop_n = 15\ntop_geographies = geography_stats.head(top_n)\n\nplt.figure(figsize=(12, 6))\nplt.barh(range(len(top_geographies)), top_geographies['Count'])\nplt.yticks(range(len(top_geographies)), top_geographies['Geography'])\nplt.xlabel('Number of Cases')\nplt.ylabel('Geography')\nplt.title(f'Top {top_n} Geographies by Case Count')\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.show()\n\n# Save statistics to CSV\ngeography_stats.to_csv('geography_statistics.csv', index=False)\nprint(\"\\nGeography statistics saved to: geography_statistics.csv\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}